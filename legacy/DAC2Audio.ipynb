{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8f21fd",
   "metadata": {},
   "source": [
    "### <font color='blue'> DAC to audio \n",
    "</font>\n",
    "\n",
    "This notebook reads a DAC file and uses the descript 44.1kHz pretrained DAC to decompress it to audio.   \n",
    "It is in a separate file from the transformer generative code because it takes up too much memory (which doesn't seem right).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43141501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "\n",
    "# and for creating a custom dataset and loader:\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import dac\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f18d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7203766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "# Function to find all tensors on CUDA\n",
    "def get_cuda_tensors():\n",
    "    cuda_tensors = []\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) and obj.is_cuda:\n",
    "                cuda_tensors.append((type(obj), obj.size()))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return cuda_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a52e4",
   "metadata": {},
   "source": [
    "### <font color='blue'> Parameters \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data dir\n",
    "\n",
    "experiment_name=\"01.20PostNormCond_2_\" #\"06.30_Keysmall\"\n",
    "cptnum=600 \n",
    "tstsnd1='bees'  # 'pistons', 'wind', 'applause', 'bees'\n",
    "tstsnd2= 'wind'\n",
    "#tstsnd2='bees'\n",
    "\n",
    "#must match a specific dac file name used\n",
    "minpval=0\n",
    "maxpval=1\n",
    "topn=1024\n",
    "\n",
    "\n",
    "inference_steps=86*20\n",
    "\n",
    "\n",
    "SAVEWAV=True\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# I am having with running out of memory loading the DAC model with cuda. CPU runs pretty fast\n",
    "# for decompressing, so there ya go. \n",
    "DEVICE='cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22201758",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE == 'cuda' :\n",
    "    torch.cuda.device_count()\n",
    "    torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "\n",
    "    device = torch.device(DEVICE) # if the docker was started with --gpus all, then can choose here with cuda:0 (or cpu)\n",
    "    torch.cuda.device_count()\n",
    "    print(f'memeory on cuda 0 is  {torch.cuda.get_device_properties(0).total_memory/1e9}')\n",
    "else :\n",
    "    device=DEVICE\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc37e0",
   "metadata": {},
   "source": [
    "### <font color='blue'> Get the DAC model \n",
    "that will be need *after* we run the transformer in order to reconstruct the signal from codes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time you do this, it can take a while. Go get coffee. After that, it uses a cached version\n",
    "dacmodel_path = dac.utils.download(model_type=\"44khz\") \n",
    "print(f'Stored the DAC decoder in {dacmodel_path}')\n",
    "with torch.no_grad():\n",
    "    dacmodel = dac.DAC.load(dacmodel_path)\n",
    "\n",
    "    dacmodel.to(device); #wanna see the model? remove the semicolon\n",
    "    dacmodel.eval();  # need to be \"in eval mode\" in order to set the number of quantizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c8afc",
   "metadata": {},
   "source": [
    "### <font color='blue'> Codes-2-Audio reconstruction\n",
    "that will be need *after* we run the transformer in order to reconstruct the signal from codes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9518a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------  derived ------ don't change these \n",
    "fname=tstsnd1+ '.' + tstsnd2 + '_chkpt_' + str(cptnum).zfill(4) + '_steps_'+str(inference_steps).zfill(4)+'.minpval_'+ f\"{minpval:01.2f}\" +'.maxpval_'+ f\"{maxpval:01.2f}\" +'.topn_'+ f\"{topn:04d}\"\n",
    "data_dir= 'runs' + '/' + experiment_name\n",
    "selected_file=data_dir+'/' + \"dacs\" + '/' + fname + \".dac\"\n",
    "print(f' fname is {fname}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    dacfile = dac.DACFile.load(selected_file)\n",
    "    # FIRST - Decompress it back to an AudioSignal\\ from codes to z (1024) to signal   \n",
    "    print(f'dacfile.codes shape is: {dacfile.codes.shape}')\n",
    "    t0=time.time()\n",
    "    asig=dacmodel.decompress(dacfile)\n",
    "    t1=time.time()\n",
    "    \n",
    "    inf_time = t1-t0\n",
    "    print(f'decompress time for {asig.audio_data.shape[2]/44100} seconds of sound is {inf_time}' )\n",
    "    print(f'asig.audio_data.shape[2] is {asig.audio_data.shape[2]}')\n",
    "    \n",
    "    asig.cpu().widget()\n",
    "    asig.save_image(data_dir+'/' + \"dacs\" + '/' + fname + \".jpg\")\n",
    "    asig.audio_data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8421203c",
   "metadata": {},
   "source": [
    "# just a check to see if we saved the jpeg as we intended to\n",
    "display(Image(filename=data_dir+'/' + \"dacs\" + '/' + fname + \".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata = asig.samples.view(-1).numpy()\n",
    "if SAVEWAV :  \n",
    "    sf.write(data_dir+'/' + \"dacs\" + '/' + fname + \".wav\", adata, 44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba014b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(adata)\n",
    "ipd.Audio(adata, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will list every variable on cuda if you are using it. \n",
    "cuda_tensors = get_cuda_tensors()\n",
    "for tensor_type, tensor_size in cuda_tensors:\n",
    "    print(f'Type: {tensor_type}, Size: {tensor_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95161d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40afc6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
