experiment: "2025.02.19_ROPE_mask86layers4fexp4"
#testsnd: "" # pistons, wind, applause, bees, chirp, toks, peep

# for docker:
data_dir: "/scratch/syntexnew/dacdata7/train_sm"
validator_data_dir: "/scratch/syntexnew/dacdata7/val"

#data_dir: "/home/lonce/scratchdata/syntexnew/dacdata7/train_sm"
#validator_data_dir: "/home/lonce/scratchdata/syntexnew/dacdata7/val"

TransformerClass: "RopeCondDACTransformer" # "PostNormCondDACTransformerDecoder" # "ClassConditionedKeyTransformer" # 

vocab_size: 1024
num_tokens: 4

cond_params: 1 #1 (not counting the classes)
model_size: 512 # must be divisible by num_heads

Ti: 86 # 172 #86
Tt: 430 # must match the length of the sequences in the batch
batch_size: 8  #**


num_layers: 4 #**
num_heads: 8 # 8 # embed_size must be divisible by num_heads
forward_expansion: 4 # 4 #4
dropout_rate: 0.2
learning_rate: 0.0005

num_epochs: 250 ### 800 

ErrorLogRate: 10 ### 10
checkpoint_interval: 25 ###50 # 25

